# LLMPapers
This repository is maintained by [Shenyu Zhang](https://github.com/ZSY-SZ) & Runzhe Wang. The automation script of this repo is powered by [Auto-Bibfile](https://github.com/wutong8023/Auto-Bibfile.git).

This page categorizes the literature by the **Last Post**.

## Outline 
- [![](https://img.shields.io/badge/Hyperlink-blue)](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/time\README.md#hyperlink)
- [![](https://img.shields.io/badge/2022-16-blue)](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/time\README.md#2022)
## Hyperlink 
- [[Overview]](https://github.com/KSESEU/LLMPapers/blob/main/README.md) -- [Homepage](https://github.com/KSESEU/LLMPapers/blob/main/README.md)
-  -- [Summary](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/./)
-  -- [Application](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/application)
-  -- [Approach](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/approach)
-  -- [Author](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/author)
-  -- [Backbone Model](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/backbone_model)
-  -- [Contribution](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/contribution)
-  -- [Dataset](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/dataset)
-  -- [Metrics](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/metrics)
-  -- [Research Questions](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/research_question)
-  -- [Setting](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/setting)
-  -- [ Learning Paradigm](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/supervision)
-  -- [Published Time](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/time)
-  -- [Published Venue](https://github.com/KSESEU/LLMPapers/blob/main/taxonomy/venue)

## 2022

- [![](https://img.shields.io/badge/ACL-2022-blue)](https://doi.org/10.18653/v1/2022.acl-long.53) [**Meta-learning via Language Model In-context Tuning**](https://doi.org/10.18653/v1/2022.acl-long.53) , <br> by *Yanda Chen and
Ruiqi Zhong and
Sheng Zha and
George Karypis and
He He*
<br><br>
- [![](https://img.shields.io/badge/CoRR-2022-blue)](https://doi.org/10.48550/arXiv.2210.12810) [**Code4Struct: Code Generation for Few-Shot Structured Prediction from
Natural Language**](https://doi.org/10.48550/arXiv.2210.12810) , <br> by *Xingyao Wang and
Sha Li and
Heng Ji*
<br><br>
- [![](https://img.shields.io/badge/CVPR-2022-blue)](https://doi.org/10.1109/CVPR52688.2022.00024) [**Learning to Prompt for Continual Learning**](https://doi.org/10.1109/CVPR52688.2022.00024) , <br> by *Zifeng Wang and
Zizhao Zhang and
Chen{-}Yu Lee and
Han Zhang and
Ruoxi Sun and
Xiaoqi Ren and
Guolong Su and
Vincent Perot and
Jennifer G. Dy and
Tomas Pfister*
<br><br>
- [![](https://img.shields.io/badge/EMNLP-2022-blue)](https://doi.org/10.48550/arXiv.2203.08568) [**In-Context Learning for Few-Shot Dialogue State Tracking**](https://doi.org/10.48550/arXiv.2203.08568) , <br> by *Yushi Hu and
Chia{-}Hsuan Lee and
Tianbao Xie and
Tao Yu and
Noah A. Smith and
Mari Ostendorf*
<br>```TODO: Update URL when formally published```<br><br>
- [![](https://img.shields.io/badge/EMNLP-2022-blue)](https://doi.org/10.48550/arXiv.2205.12673) [**Improving Zero and Few-shot Generalization in Dialogue through Instruction
Tuning**](https://doi.org/10.48550/arXiv.2205.12673) , <br> by *Prakhar Gupta and
Cathy Jiao and
Yi{-}Ting Yeh and
Shikib Mehri and
Maxine Esk{\'{e}}nazi and
Jeffrey P. Bigham*
<br>```TODO: Update URL when formally published```<br><br>
- [![](https://img.shields.io/badge/EMNLP-2022-blue)](https://arxiv.org/abs/2202.12837) [**Rethinking the Role of Demonstrations: What Makes In-Context Learning
Work?**](https://arxiv.org/abs/2202.12837) , <br> by *Sewon Min and
Xinxi Lyu and
Ari Holtzman and
Mikel Artetxe and
Mike Lewis and
Hannaneh Hajishirzi and
Luke Zettlemoyer*
<br>```TODO: Update URL when formally published```<br><br>
- [![](https://img.shields.io/badge/CoRR-2022-blue)](https://doi.org/10.48550/arXiv.2210.07128) [**Language Models of Code are Few-Shot Commonsense Learners**](https://doi.org/10.48550/arXiv.2210.07128) , <br> by *Aman Madaan and
Shuyan Zhou and
Uri Alon and
Yiming Yang and
Graham Neubig*
<br><br>
- [![](https://img.shields.io/badge/NAACL-2022-blue)](https://doi.org/10.18653/v1/2022.naacl-main.167) [**Do Prompt-Based Models Really Understand the Meaning of Their Prompts?**](https://doi.org/10.18653/v1/2022.naacl-main.167) , <br> by *Albert Webson and
Ellie Pavlick*
<br><br>
- [![](https://img.shields.io/badge/NAACL-2022-blue)](https://doi.org/10.18653/v1/2022.naacl-main.201) [**MetaICL: Learning to Learn In Context**](https://doi.org/10.18653/v1/2022.naacl-main.201) , <br> by *Sewon Min and
Mike Lewis and
Luke Zettlemoyer and
Hannaneh Hajishirzi*
<br><br>
- [![](https://img.shields.io/badge/NeurIPS-2022-blue)](https://doi.org/10.48550/arXiv.2209.12356) [**News Summarization and Evaluation in the Era of GPT-3**](https://doi.org/10.48550/arXiv.2209.12356) , <br> by *Tanya Goyal and
Junyi Jessy Li and
Greg Durrett*
<br><br>
- [![](https://img.shields.io/badge/NeurIPS-2022-blue)](https://doi.org/10.48550/arXiv.2210.09338) [**Deep Bidirectional Language-Knowledge Graph Pretraining**](https://doi.org/10.48550/arXiv.2210.09338) , <br> by *Michihiro Yasunaga and
Antoine Bosselut and
Hongyu Ren and
Xikun Zhang and
Christopher D. Manning and
Percy Liang and
Jure Leskovec*
<br>```TODO: Update URL when formally published```<br><br>
- [![](https://img.shields.io/badge/CoRR-2022-blue)](https://doi.org/10.48550/arXiv.2209.01975) [**Selective Annotation Makes Language Models Better Few-Shot Learners**](https://doi.org/10.48550/arXiv.2209.01975) , <br> by *Hongjin Su and
Jungo Kasai and
Chen Henry Wu and
Weijia Shi and
Tianlu Wang and
Jiayi Xin and
Rui Zhang and
Mari Ostendorf and
Luke Zettlemoyer and
Noah A. Smith and
Tao Yu*
<br><br>
- [![](https://img.shields.io/badge/VLDB-2022-blue)](https://www.vldb.org/pvldb/vol15/p1466-li.pdf) [**Selective Data Acquisition in the Wild for Model Charging**](https://www.vldb.org/pvldb/vol15/p1466-li.pdf) , <br> by *Chengliang Chai and
Jiabin Liu and
Nan Tang and
Guoliang Li and
Yuyu Luo*
<br><br>
- [![](https://img.shields.io/badge/CoRR-2022-blue)](https://doi.org/10.48550/arXiv.2212.09420) [**When Neural Model Meets NL2Code: A Survey**](https://doi.org/10.48550/arXiv.2212.09420) , <br> by *Daoguang Zan and
Bei Chen and
Fengji Zhang and
Dianjie Lu and
Bingchao Wu and
Bei Guan and
Yongji Wang and
Jian{-}Guang Lou*
<br><br>
- [![](https://img.shields.io/badge/TKDE-2022-blue)](https://doi.org/10.48550/arXiv.2212.13428) [**A Survey on Knowledge-Enhanced Pre-trained Language Models**](https://doi.org/10.48550/arXiv.2212.13428) , <br> by *Chaoqi Zhen and
Yanlei Shang and
Xiangyu Liu and
Yifei Li and
Yong Chen and
Dell Zhang*
<br>```TODO: Update URL when formally published```<br><br>
- [![](https://img.shields.io/badge/FCST-2022-blue)](https://doi.org/10.3778/j.issn.1673-9418.2108105) [**Review of Knowledge-Enhanced Pre-trained Language Models**](https://doi.org/10.3778/j.issn.1673-9418.2108105) , <br> by *Yi, HAN, Linbo, QIAO, Dongsheng, LI and Xiangke, LIAO*
<br><br>